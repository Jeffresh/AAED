{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter17-gc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoVZNjgi+qioI54wZoWTld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d078cc2f79a4d5fb8d2af925becddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7a4ac378f094abb8500c21c60de5cc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d92dba180dd4008953ad3264a1d0ecb",
              "IPY_MODEL_9d3817b5804e4f3da74434ff619047e8"
            ]
          }
        },
        "e7a4ac378f094abb8500c21c60de5cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d92dba180dd4008953ad3264a1d0ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3d836ef033e45889416a968e86cce16",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c83536099d8346988a7fd34cf4644d52"
          }
        },
        "9d3817b5804e4f3da74434ff619047e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d6dfffa845141528e8303ad3f73228f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  4.82 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_660b011b84f0430aabaad586bce4d235"
          }
        },
        "d3d836ef033e45889416a968e86cce16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c83536099d8346988a7fd34cf4644d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d6dfffa845141528e8303ad3f73228f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "660b011b84f0430aabaad586bce4d235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeffresh/AAED/blob/master/chapter17/Chapter17_gc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_pfADoubI1I"
      },
      "source": [
        "# Generative Adversarial Networks (Gans) for Synthesizing New Data \n",
        "\n",
        "- Introducing generative models for synthesizing new data\n",
        "- Autoencoders, variational autoencoders (VAEs) , and thei relationships to GANs\n",
        "- Understanding the building bloks og GANs\n",
        "- Implementing a simple GAN model to gnerate handwritten digits\n",
        "- Understanding transposed convolution and *batch normalization (BATchNorm or BN)\n",
        "- Improving GANs: deep convolutional GANs and GANs using the Wasserstein distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh2ohQg_ca6z"
      },
      "source": [
        "### Install Tensorflow 2.0 with  gpu support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvz9gSddchmt"
      },
      "source": [
        "! pip install -q tensorflow-gpu>=2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOFvQ4X9brM_",
        "outputId": "a5a13024-819f-4fc4-9f2d-63a7457da6e5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgdFvtqOcCH2",
        "outputId": "923ef5d2-858a-406b-91bf-75cadc971b8a"
      },
      "source": [
        "print('GPU Available: ', tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ty92lBeeAaq",
        "outputId": "40dfb6c7-d127-46f3-e1b9-66214093a5d7"
      },
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "else:\n",
        "  device_name = '/CPU: 0'\n",
        "\n",
        "print(device_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UzKTvzRfreN"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbXErNZMf5Gw"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZPBVOvoeKxU"
      },
      "source": [
        "## Implementing the generator and the discriminator networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuibgpqUgivU"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z9hmjt8gm6B"
      },
      "source": [
        "## define a function for the generator:\n",
        "def make_generator_network(num_hidden_layers=1, num_hidden_units=100, num_output_units=784):\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  for i in range(num_hidden_layers):\n",
        "    model.add(\n",
        "        tf.keras.layers.Dense(\n",
        "            units=num_hidden_units, use_bias=False))\n",
        "    \n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "  \n",
        "  model.add(\n",
        "      tf.keras.layers.Dense(\n",
        "          units=num_output_units, activation='tanh'\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvNRM3oMhRh6"
      },
      "source": [
        "## Define a function fo r the discriminator:\n",
        "\n",
        "def make_discriminator_network(num_hidden_layers=1, num_hidden_units=100, num_output_units=1):\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  for i in range(num_hidden_layers):\n",
        "    model.add(\n",
        "        tf.keras.layers.Dense(units=num_hidden_units)\n",
        "    )\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "  \n",
        "  model.add(\n",
        "      tf.keras.layers.Dense(\n",
        "          units=num_output_units, activation=None\n",
        "      )\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtWXfE2uiIoR"
      },
      "source": [
        "image_size = (28, 28)\n",
        "z_size = 20\n",
        "mode_z = 'uniform' # 'uniform' vs. 'normal'\n",
        "gen_hidden_layers = 1\n",
        "gen_hidden_size= 100\n",
        "disc_hidden_layers = 1\n",
        "disc_hidden_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUiVrfsvilSI"
      },
      "source": [
        "tf.random.set_seed(1)\n",
        "\n",
        "gen_model = make_generator_network(\n",
        "    num_hidden_layers=gen_hidden_layers,\n",
        "    num_hidden_units=gen_hidden_size,\n",
        "    num_output_units=np.prod(image_size)\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pc1bsdXiwUx",
        "outputId": "511c50cb-933b-4145-cc3a-e7ff3c6758d2"
      },
      "source": [
        "gen_model.build(input_shape=(None, z_size))\n",
        "gen_model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              multiple                  2000      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             multiple                  79184     \n",
            "=================================================================\n",
            "Total params: 81,184\n",
            "Trainable params: 81,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvo_rYerjNFW"
      },
      "source": [
        "disc_model = make_discriminator_network(num_hidden_layers=disc_hidden_layers, num_hidden_units=disc_hidden_size)\n",
        "disc_model.build(input_shape=(None, np.prod(image_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyVVEROdjWmK",
        "outputId": "0f028a79-b550-4164-e3c0-7f9bb48380fa"
      },
      "source": [
        "disc_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              multiple                  78500     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  101       \n",
            "=================================================================\n",
            "Total params: 78,601\n",
            "Trainable params: 78,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGXWj65Ojf9Z"
      },
      "source": [
        "## Defining the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "0d078cc2f79a4d5fb8d2af925becddce",
            "e7a4ac378f094abb8500c21c60de5cc2",
            "8d92dba180dd4008953ad3264a1d0ecb",
            "9d3817b5804e4f3da74434ff619047e8",
            "d3d836ef033e45889416a968e86cce16",
            "c83536099d8346988a7fd34cf4644d52",
            "4d6dfffa845141528e8303ad3f73228f",
            "660b011b84f0430aabaad586bce4d235"
          ]
        },
        "id": "xWnm0T-ikqAk",
        "outputId": "6acd696a-c85e-4e8f-d062-73b4f7ef8dc3"
      },
      "source": [
        "mnist_bldr = tfds.builder('mnist')\n",
        "mnist_bldr.download_and_prepare()\n",
        "mnist = mnist_bldr.as_dataset(shuffle_files=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d078cc2f79a4d5fb8d2af925becddce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc6HPIXjk9lI"
      },
      "source": [
        "def preprocess(ex, mode='uniform'):\n",
        "  image = ex['image']\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.reshape(image, [-1])\n",
        "  image = image * 2 - 1.0\n",
        "  if mode == 'uniform':\n",
        "    input_z = tf.random.uniform(\n",
        "        shape=(z_size,), minval=-1.0, maxval=1.0)\n",
        "  elif mode == 'normal':\n",
        "    input_z = tf.random.normal(shape=(z_size, ))\n",
        "  \n",
        "  return input_z, image"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lL0nHicloGr"
      },
      "source": [
        "mnist_trainset = mnist['train']\n",
        "mnist_trainset = mnist_trainset.map(preprocess)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suZXRkHll19V",
        "outputId": "7c2239bb-41c0-4606-84ef-2a6dbcc552be"
      },
      "source": [
        "mnist_trainset = mnist_trainset.batch(32, drop_remainder=True)\n",
        "input_z, input_real = next(iter(mnist_trainset))\n",
        "print('input-z -- shape:   ', input_z.shape)\n",
        "print('input-real -- shape:', input_real.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input-z -- shape:    (32, 20)\n",
            "input-real -- shape: (32, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvQtA_AimtYI",
        "outputId": "e75b1433-95e1-4700-ae07-87b197a7a729"
      },
      "source": [
        "g_output = gen_model(input_z)\n",
        "print('Output of G -- shape:', g_output.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of G -- shape: (32, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoHlezwrnEBN",
        "outputId": "eff75281-40da-41cb-ccf0-b59fb16370b0"
      },
      "source": [
        "d_logits_real = disc_model(input_real)\n",
        "d_logits_fake = disc_model(g_output)\n",
        "print('Disc. (real) -- shape:', d_logits_real.shape)\n",
        "print('Disc. (fake) -- shape:', d_logits_fake.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Disc. (real) -- shape: (32, 1)\n",
            "Disc. (fake) -- shape: (32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdInJ8Z6nGbl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}